# ğŸš€ Groq CLI Chatbot

A lightning-fast command-line interface chatbot powered by **Groq's LPU Inference Engine** and **Meta's Llama 3.3 70B** model.

## âœ¨ Features
- **Ultra-Low Latency:** Instant responses thanks to Groq's hardware.
- **Persistent History:** Remembers the conversation context during the session.
- **Streaming Output:** Real-time text generation (typing effect).
- **Secure:** Uses environment variables to keep your API keys safe.

## ğŸ› ï¸ Tech Stack
- **Language:** Python 3.x
- **Inference Engine:** [Groq Cloud](https://console.groq.com/)
- **Model:** `llama-3.3-70b-versatile`
- **Libraries:** `groq`, `python-dotenv`

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone (https://github.com/olumo-oke/groq-cli-bot.git)

### 2. Install dependencies
pip install -r requirements.txt

### 1. Environment Variables
Create a .env file in the root directory and add your Groq API Key:

4. Run the Bot
```Bash
python main.py

ğŸ¤ Contributing
Feel free to fork this project and submit pull requests! Suggestions for new features like chat logging or voice integration are welcome.

ğŸ“„ License
MIT License


---

### 3. Final Commit and Push
Now that you've added the README, you should commit it and send it to GitHub so your profile looks complete.

```cmd
git add README.md
git commit -m "docs: add comprehensive README"
git push
